{"cells": [{"cell_type": "code", "id": "172cb81a-e6ca-4d7b-815d-afe7a5bd48dc", "source": ["# This cell is NOT editable. Overwrite variables on your own discretion.\n# Any changes other than the script code will NOT BE SAVED!\n# All cells are assumed to be script code cells, unless explictly tagged as 'o9_ignore'"], "metadata": {"editable": false}, "tags": ["o9_ignore"]}, {"cell_type": "code", "id": "ccb49e85-e27e-47e1-a65e-368fda700b78", "source": ["_factTable = \"Select ([Supplier].[Supplier Location] * [Activity2].[Activity2] * [Location].[Location] * [Documents].[OrderlineID] * [Item].[Item] * [Version].[Version Name] * [Time].[Day] ) on row,  ({Measure.[AL PO % of Total Goods Receipt TG], Measure.[AL PO % of Total Purchase Value TG], Measure.[AL PO % of Total Unique Goods Purchased TG], Measure.[AL PO Commit Creation Date TG], Measure.[AL PO Commit Delivery Date TG], Measure.[AL PO Commit Delivery Qty TG], Measure.[AL PO Goods Receipt Date TG], Measure.[AL PO Goods Receipt Purchase Value TG], Measure.[AL PO Goods Receipt Quantity TG], Measure.[AL PO Header Creation Date TG], Measure.[AL PO Net Price Per Unit TG], Measure.[AL PO Unique Goods Purchased TG]}) on column;\"\n\n\n# Initialize the O9DataLake with the input parameters and dataframes\n# Data can be accessed with O9DataLake.get(<Input Name>)\n# Overwritten values will not be reflected in the O9DataLake after initialization\n\nfrom o9_common_utils.O9DataLake import O9DataLake, ResourceType, DataSource\nfactTable = O9DataLake.register(\"factTable\",DataSource.LS, ResourceType.IBPL, _factTable)"], "metadata": {"tags": ["o9_ignore"]}, "tags": ["o9_ignore"]}, {"cell_type": "code", "id": "7fc9ac2a-b1f8-4281-ae26-2e1d4f972484", "source": ["import pandas as pd\nimport logging\nimport random\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import KMeans\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import ExtraTreeRegressor\nfrom o9helpers import user_storage_path\nfrom o9storage import cloud_storage_utils, storage_utils\nimport pickle\nimport os\nimport shutil\n\n\nlogger = logging.getLogger('o9_logger')\nlogger.info('===== ITEM CLUSTERING SCRIPT ======')\n\n\ndef is_outlier(s):\n    list_ = np.array(s)\n    std_ = np.std(list_)\n    if(np.isnan(std_)==True):\n        lower_limit = s.mean()\n        upper_limit = s.mean()\n    else:\n        lower_limit = s.mean() - (std_ * 2)\n        upper_limit = s.mean() + (std_ * 2)\n    return ~s.between(lower_limit, upper_limit)\n\n\nversionName = factTable['Version.[Version Name]'].iloc[0]\n\nlogger.info('===== VERSION NAME ======')\nlogger.info(versionName)\n\nfactTable = factTable[[\"Supplier.[Supplier Location]\",\"Activity2.[Activity2]\",\n                       \"Location.[Location]\",\"Item.[Item]\",\"Time.[Day]\",\n                      \"AL PO Header Creation Date TG\",\"AL PO Goods Receipt Date TG\",\"AL PO Net Price Per Unit TG\"]]\n\n\nlogger.info(factTable.head())\nlogger.info(factTable.dtypes)\n\nfactTable['AL PO Goods Receipt Date TG'] = pd.to_datetime(factTable['AL PO Goods Receipt Date TG'])\nfactTable['AL PO Header Creation Date TG'] = pd.to_datetime(factTable['AL PO Header Creation Date TG'])\nfactTable['LeadTime'] = (factTable['AL PO Goods Receipt Date TG'] - factTable['AL PO Header Creation Date TG']).dt.days\n\nfactTable['Supplier.[Supplier]'] = factTable['Supplier.[Supplier Location]']\nfactTable = factTable.drop(['Supplier.[Supplier Location]'],axis=1)\nfactTable['year'] = factTable['AL PO Header Creation Date TG'].dt.year\n\nfactTable = factTable.drop(['AL PO Header Creation Date TG','AL PO Goods Receipt Date TG'],axis=1)\nfactTable['Time.[Day]'] = pd.to_datetime(factTable['Time.[Day]'])\nfactTable['Month'] = factTable['Time.[Day]'].apply(lambda x: x.strftime(\"%b\"))\n\nfactTable = factTable.drop([\"Time.[Day]\"],axis=1)\n\n####### Removing Outliers ##############\n\nfactTable = factTable[~factTable.groupby('Item.[Item]')['LeadTime'].apply(is_outlier)]\n\n##### Clustering  ######\n\nnewForCluster = factTable.groupby(\"Item.[Item]\").agg({\"LeadTime\":\"mean\",\"AL PO Net Price Per Unit TG\":\"mean\"}).reset_index()\n\nkmeanModel = KMeans(n_clusters=60)\nkmeanModel.fit(newForCluster.drop([\"Item.[Item]\"],axis=1))\nnewForCluster['Cluster']=kmeanModel.predict(newForCluster.drop([\"Item.[Item]\"],axis=1))\n\nItemCluster = newForCluster[[\"Item.[Item]\",\"Cluster\"]]\n\nlogger.info(\"*** Clusters *****\")\nlogger.info(ItemCluster)\n\nItemCluster[\"Version.[Version Name]\"] = versionName\n\nItemCluster = ItemCluster[[\"Version.[Version Name]\",\"Item.[Item]\",\"Cluster\"]]\n\n\nlogger.info(\"============ Clusters Calculated ============\")\nlogger.info(ItemCluster[\"Cluster\"].unique())\nlogger.info(ItemCluster.head(12))\n\n\nlogger.info(\"=========== Clustering Completed ==========\")"], "metadata": {}}], "metadata": {"kernelspec": {"display_name": "ComcastXMDataSciDev", "language": "python", "name": "ComcastXMDataSciDev"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.10"}, "notebook_dict": {"file_path": "loaded_notebooks/AnalyticsPO001ItemClustering.ipynb", "ClassName": "o9.GraphCube.Plugins.Python.PythonScript", "InstanceName": "AnalyticsPO001ItemClustering", "SliceKeys": [], "o9_selected_plugin_id": 14832}}, "nbformat": 4, "nbformat_minor": 5}